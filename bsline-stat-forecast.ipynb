{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HrvQysecM9my"
   },
   "source": [
    "# Statistical Analysis and Forecasting on Sunspots Time Series\n",
    "\n",
    "In this lab, you will be doing some statistical forecasting so you can compare it with the machine learning models you will build later on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9x4GjlEVTQN"
   },
   "source": [
    "## Imports\n",
    "\n",
    "You will first import the packages you will need to execute all the code in this lab. You will use:\n",
    "* [Tensorflow](https://www.tensorflow.org/api_docs/python/tf) to build your model and prepare data windows\n",
    "* [Numpy](https://numpy.org/) for numerical processing\n",
    "* and Matplotlib's [PyPlot](https://matplotlib.org/3.5.1/api/_as_gen/matplotlib.pyplot.html) library for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "L1EqtpHwMhD2"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzdoFsd3NRX5"
   },
   "source": [
    "## Utilities\n",
    "\n",
    "You will then define some utility functions to make the code more organized. First up is the plotting function you also used in the previous lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series(x, y, start=0, end=None, figsize=(16, 5),\n",
    "                title=None, xlabel=None, ylabel=None, \n",
    "                legend=None, linestyle='-', color=None, \n",
    "                xlim=None, ylim=None):\n",
    "    \"\"\"\n",
    "    Visualizes time series data\n",
    "\n",
    "    Args:\n",
    "      x (array of int) - contains values for the x-axis\n",
    "      y (array of int or tuple of arrays) - contains the values for the y-axis\n",
    "      linestyle (string) - line style when plotting the graph\n",
    "      label (string) - tag for the line\n",
    "      start (int) - first time step to plot\n",
    "      end (int) - last time step to plot\n",
    "      title (string) - title of the plot\n",
    "      xlabel (string) - label for the x-axis\n",
    "      ylabel (string) - label for the y-axis\n",
    "      legend (list of strings) - legend for the plot\n",
    "    \"\"\"\n",
    "\n",
    "    # Setup dimensions of the graph figure\n",
    "    plt.figure(figsize=figsize, dpi=360)\n",
    "    \n",
    "    # Check if there are more than two series to plot\n",
    "    if type(y) is tuple:\n",
    "\n",
    "      # Loop over the y elements\n",
    "      for y_curr in y:\n",
    "\n",
    "        # Plot the x and current y values\n",
    "        plt.plot(x[start:end], y_curr[start:end], linestyle=linestyle, color=color)\n",
    "\n",
    "    else:\n",
    "      # Plot the x and y values\n",
    "      plt.plot(x[start:end], y[start:end], linestyle=linestyle, color=color)\n",
    "    \n",
    "    if xlim:\n",
    "      plt.xlim(xlim)\n",
    "    if ylim:\n",
    "      plt.ylim(ylim)\n",
    "\n",
    "    # Label the x-axis\n",
    "    plt.xlabel(xlabel)\n",
    "\n",
    "    # Label the y-axis\n",
    "    plt.ylabel(ylabel)\n",
    "\n",
    "    # Set the legend\n",
    "    if legend:\n",
    "      plt.legend(legend)\n",
    "\n",
    "    # Set the title\n",
    "    plt.title(title, fontsize=20)\n",
    "\n",
    "    # Overlay a grid on the graph\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Draw the graph on screen\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nk1l6rCEwFK1"
   },
   "source": [
    "You will also place the functions to generate your synthetic data here. For this lab, you will just need trend, seasonality, and noise. Feel free to add others later in case you want a more challenging task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab and the next, you will only need the month number and the mean total sunspot number. You will load those into memory and convert it to arrays that represents a time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists\n",
    "time_stamp = []\n",
    "sunspots = []\n",
    "\n",
    "# Open CSV file\n",
    "with open('./Sunspots.csv') as csvfile:\n",
    "  \n",
    "  # Initialize reader\n",
    "  reader = csv.reader(csvfile, delimiter=',')\n",
    "  \n",
    "  # Skip the first line\n",
    "  next(reader)\n",
    "  \n",
    "  # Append row and sunspot number to lists\n",
    "  for row in reader:\n",
    "    time_stamp.append(int(row[0]))\n",
    "    sunspots.append(float(row[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to numpy arrays\n",
    "time = np.array(time_stamp)\n",
    "series = np.array(sunspots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preview the data\n",
    "plot_series(time, series, figsize=(16, 5),\n",
    "            title='Sunspots Observation by Month', \n",
    "            xlabel='Month', \n",
    "            ylabel='Monthly Mean Total Sunspot Number', \n",
    "            color='orange',\n",
    "            # xlim=(245, 250)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Dataset\n",
    "\n",
    "Next up, you will split the data above into training and validation sets. You will take the first 1,000 points for training while the rest is for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the split time\n",
    "split_time = 3000\n",
    "\n",
    "# Get the train set \n",
    "time_train = time[:split_time]\n",
    "x_train = series[:split_time]\n",
    "\n",
    "# Get the validation set\n",
    "time_valid = time[split_time:]\n",
    "x_valid = series[split_time:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect these sets visually by using the same utility function for plotting. Notice that in general, the validation set has higher values (i.e. y-axis) than those in the training set. Your model should be able to predict those values just by learning from the trend and seasonality of the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series analysis using statistical tools and techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two side view - To emphasize the trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16, 5), dpi=360)\n",
    "ax.fill_between(time, y1=series, y2=-series, alpha=0.5, linewidth=2, color='seagreen')\n",
    "ax.axis(ymin=-600, ymax=600)\n",
    "ax.set_title('Trend of sunspots (Two-side View)', fontsize=16)\n",
    "ax.hlines(y=0, xmin=np.min(time), xmax=np.max(time), linewidth=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that its a monthly time series and follows a certain repetitive pattern every couple years. \n",
    "\n",
    "Meanwhile, there is no clear growing or decreasing trend in the chart. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition of the Time Series\n",
    "\n",
    "Additive or Multiplicative combination of the base level, trend, seasonal index and the residual term. \n",
    "\n",
    "**Additive time series:**\n",
    "\n",
    "Value = Base Level + Trend + Seasonality + Error\n",
    "\n",
    "**Multiplicative Time Series:**\n",
    "\n",
    "Value = Base Level x Trend x Seasonality x Error\n",
    "\n",
    "We  will apply the seasonal_decompose module in the package statsmodels to find out the values of these attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose as sd \n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplicative Decomposition\n",
    "# multi_decomp = sd(series, model='multiplicative', period=30)\n",
    "\n",
    "# Additive Decomposition\n",
    "add_decomp = sd(series,model='additive', period=150)\n",
    "\n",
    "# Plot\n",
    "plt.rcParams.update({'figure.figsize': (16,12), 'figure.dpi': 360, 'axes.titlesize': 24})\n",
    "add_decomp.plot()\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "# fig_decomp = add_decomp.plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additive Decomposition\n",
    "add_decomp = sd(series,model='additive', period=30)\n",
    "\n",
    "# Plot\n",
    "plt.rcParams.update({'figure.figsize': (16,12), 'figure.dpi': 360, 'axes.titlesize': 24})\n",
    "add_decomp.plot()\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stationary, Non-stationary Time Series and Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test for stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "stat_res = adfuller(series, autolag='AIC')\n",
    "print(f'ADF Statistic: {stat_res[0]:.2f}')\n",
    "print(f'n_lags: {stat_res[1]:.2e}')\n",
    "print(f'p-value: {stat_res[1]:.2e}')\n",
    "for key, value in stat_res[4].items():\n",
    "    print('Critial Values:')\n",
    "    print(f'   {key}, {value:.3f}') \n",
    "\n",
    "print(f'\\nThe p-value is less than 0., thus, the series is NON-stationary.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deseasonalise a Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Decomposition\n",
    "deseason = series / add_decomp.seasonal\n",
    "\n",
    "# Plot\n",
    "fig_sea, ax_sea = plt.subplots(1, 1, dpi=480, figsize=(14, 5))\n",
    "\n",
    "ax_sea.set_title('Sunspots Time Series Deseasonalised', fontsize=20)\n",
    "ax_sea.plot(deseason, color='lightcoral', label='Deseasonalised', linewidth=0.5)\n",
    "ax_sea.plot(series, label='Original')\n",
    "ax_sea.set_xlabel('Time', fontsize=16)\n",
    "ax_sea.set_ylabel('Sunspots', fontsize=16)\n",
    "ax_sea.legend(fontsize=14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjD8ncEZbjEW"
   },
   "source": [
    "# Naive Forecast\n",
    "\n",
    "As a baseline, you can do a naive forecast where you assume that the next value will be the same as the previous time step. You can slice the original series like below and print some values as a sanity check. The next time step value should be identical to the ground truth at the previous time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pj_-uCeYxcAb"
   },
   "outputs": [],
   "source": [
    "# Generate the naive forecast\n",
    "naive_forecast = series[split_time - 1:-1]\n",
    "\n",
    "# Define time step\n",
    "time_stamp = 100\n",
    "\n",
    "# Print values\n",
    "print(f'ground truth at time step {time_stamp}: {x_valid[time_stamp]}')\n",
    "print(f'prediction at time step {time_stamp + 1}: {naive_forecast[time_stamp + 1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YtGUyT3B2PT6"
   },
   "source": [
    "You can see this visually with the `plot_series()` function you defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vk51IA7z1Ym9"
   },
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plot_series(time_valid, (x_valid, naive_forecast), title='Native Prediction', legend=['ground truth', 'native prediction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jn-IT9pWZ1xQ"
   },
   "source": [
    "You can zoom in at the start of the validation period to see that the naive forecast lags 1 step behind the time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uh_7244Gsxfx"
   },
   "source": [
    "### Computing Metrics\n",
    "\n",
    "Now you will compute the [mean squared error](https://www.tensorflow.org/api_docs/python/tf/keras/losses/MSE) and the [mean absolute error](https://www.tensorflow.org/api_docs/python/tf/keras/losses/MAE) between the forecasts and the predictions in the validation period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "byNnC7IbsnMZ"
   },
   "outputs": [],
   "source": [
    "print(tf.keras.metrics.mse(x_valid, naive_forecast).numpy())\n",
    "print(tf.keras.metrics.mae(x_valid, naive_forecast).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "goTJyTdw3PP5"
   },
   "source": [
    "The values above will be your baseline and you will see if you can use other methods to do better than naive forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGPBC9QttI1u"
   },
   "source": [
    "## Moving Average\n",
    "\n",
    "One technique you can use is to do a moving average. This sums up a series of time steps and the average will be the prediction for the next time step. For example, the average of the measurements at time steps 1 to 10 will be the forecast for time step 11, then the average for time steps 2 to 11 will be the forecast for time step 12, and so on.\n",
    "\n",
    "The function below does the moving average for the entire `series`. It takes a `window_size` argument to indicate the number of time steps to consider when computing the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "YGz5UsUdf2tV"
   },
   "outputs": [],
   "source": [
    "def moving_average_forecast(series, window_size):\n",
    "    \"\"\"Generates a moving average forecast\n",
    "\n",
    "    Args:\n",
    "      series (array of float) - contains the values of the time series\n",
    "      window_size (int) - the number of time steps to compute the average for\n",
    "\n",
    "    Returns:\n",
    "      forecast (array of float) - the moving average forecast\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize a list\n",
    "    forecast = []\n",
    "    \n",
    "    # Compute the moving average based on the window size\n",
    "    for time in range(len(series) - window_size):\n",
    "      forecast.append(series[time:time + window_size].mean())\n",
    "    \n",
    "    # Convert to a numpy array\n",
    "    forecast = np.array(forecast)\n",
    "\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjiVlKXA5UXK"
   },
   "source": [
    "You will use this function to generate the forecast with a window size of `30`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the moving average forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HHFhGXQji7_r"
   },
   "outputs": [],
   "source": [
    "# Set time window\n",
    "window_size = 30\n",
    "\n",
    "# Include window_size data points before split time so moving average is same length as original data\n",
    "moving_avg = moving_average_forecast(series, window_size)[split_time - window_size:] \n",
    "print(f'Num of timesteps in moving_avg: {len(moving_avg)}')\n",
    "print(f'Num of timesteps in series: {len(x_valid)}')\n",
    "# Plot the results\n",
    "plot_series(time_valid, (x_valid, moving_avg), title='Moving Avg Prediction', legend=['orginal', 'moving avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wG7pTAd7z0e8"
   },
   "outputs": [],
   "source": [
    "# Compute the metrics\n",
    "print(f'MSE = {tf.keras.metrics.mse(x_valid, moving_avg).numpy()}')\n",
    "print(f'MAE = {tf.keras.metrics.mae(x_valid, moving_avg).numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMYPnJqwz8nS"
   },
   "source": [
    "That's worse than the naive forecast! The moving average does not anticipate trend or seasonality. In particular, those huge spikes in the original series causes big deviations as shown in the plot above. You will try to remove these characteristics of the dataset with time differencing and see if you get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTD4ATkFYNZp"
   },
   "source": [
    "## Differencing\n",
    "\n",
    "Since the seasonality period is 365 days, you will subtract the value at time *t* – 365 from the value at time *t*. That is done with the code below. \n",
    "\n",
    "In addition, you will need to align the result with the `time` array. Since you can only do time differencing for `t >= 365`, you will need to truncate the first 365 time steps of the `time` array.\n",
    "\n",
    "You can plot the result to visualize the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5pqySF7-rJR4"
   },
   "outputs": [],
   "source": [
    "# Set seasonal peirod\n",
    "season = 120\n",
    "\n",
    "# Subtract the values at t-132 from original series\n",
    "diff_series = (series[season:] - series[:-season])\n",
    "\n",
    "# Truncate the first 132 time steps\n",
    "diff_time = time[season:]\n",
    "\n",
    "# Plot the results\n",
    "plot_series(diff_time, diff_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPlPlS7DskWg"
   },
   "source": [
    "Great! The trend and seasonality seem to be gone so now you can retry using the moving average. `diff_series` is the ground truth while `diff_moving_avg` is the prediction array. You will slice these accordingly to correspond to the validation set time steps before comparing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QmZpz7arsjbb"
   },
   "outputs": [],
   "source": [
    "# Generate moving average from the time differenced dataset\n",
    "diff_moving_avg = moving_average_forecast(diff_series, window_size)\n",
    "\n",
    "# Slice the prediction points that corresponds to the validation set time steps\n",
    "diff_moving_avg = diff_moving_avg[split_time - season - window_size:]\n",
    "\n",
    "# Slice the ground truth points that corresponds to the validation set time steps\n",
    "diff_series = diff_series[split_time - season:]\n",
    "\n",
    "# Plot the results\n",
    "plot_series(time_valid, (diff_series, diff_moving_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gno9S2lyecnc"
   },
   "source": [
    "Now you will bring bring back the trend and seasonality by adding the past values from `t – 365`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dv6RWFq7TFGB"
   },
   "outputs": [],
   "source": [
    "# Add the trend and seasonality from the original series\n",
    "diff_moving_avg_plus_past = series[split_time - season:-season] + diff_moving_avg\n",
    "\n",
    "# Plot the results\n",
    "plot_series(time_valid, (x_valid, diff_moving_avg_plus_past))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "59jmBrwcTFCx"
   },
   "outputs": [],
   "source": [
    "print(f'MSE = {tf.keras.metrics.mse(x_valid, diff_moving_avg_plus_past).numpy()}')\n",
    "print(f'MAE = {tf.keras.metrics.mae(x_valid, diff_moving_avg_plus_past).numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYAa521hAeiC"
   },
   "source": [
    "It is a bit better than naive forecast. However, the forecasts look a bit too random because you're adding past values which are already noisy. Remember that the time differenced signal is also noisy so adding these raw past values can compound this problem. To remedy that, you can use a moving averaging on past values to smooth out some of this noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vx9Et1Hkeusl"
   },
   "source": [
    "## Smoothing\n",
    "\n",
    "You can use the same `moving_average_forecast()` function to smooth out past values before adding them back to the time differenced moving average. There are two ways to do this:\n",
    "\n",
    "* Trailing windows - This refers to getting the mean of past values to smooth out the value at the current time step. For example, getting the average of `t=0` to `t=6` to get the smoothed data point at **`t=6`**.\n",
    "\n",
    "* Centered windows - This refers to getting the mean of past *and future* values to smooth out the value at the current time step. For example, getting the average of `t=0` to `t=6` to get the smoothed data point at **`t=3`**.\n",
    "\n",
    "The code below will use the centered windows approach and you will notice it in the slicing of the `series` array. It is shifted by `370` steps and the window size is `11`. To get the smooth data point at `t=1000` (i.e. start of the validation set), it will average the measurements at `t=995` to `t=1005`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K81dtROoTE_r"
   },
   "outputs": [],
   "source": [
    "# Smooth the original series before adding the time differenced moving average\n",
    "diff_moving_avg_plus_smooth_past = moving_average_forecast(series[split_time - season - int(window_size / 2):-season + int(window_size / 2)], window_size) + diff_moving_avg\n",
    "\n",
    "# Plot the results\n",
    "plot_series(time_valid, (x_valid, diff_moving_avg_plus_smooth_past))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feGsr5IBD6c2"
   },
   "source": [
    "The metrics will show a big improvement over the previous output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iN2MsBxWTE3m"
   },
   "outputs": [],
   "source": [
    " # Compute the metrics\n",
    "print(f'MSE = {tf.keras.metrics.mse(x_valid, diff_moving_avg_plus_smooth_past).numpy()}')\n",
    "print(f'MAE = {tf.keras.metrics.mae(x_valid, diff_moving_avg_plus_smooth_past).numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHTiSidU-b8g"
   },
   "source": [
    "## Wrap Up\n",
    "\n",
    "This concludes a short exploration of statistical methods for time series forecasting. In the next labs, you will build neural networks for forecasting and see if you get comparable results to the techniques you just used in this lab."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "C4_W1_Lab_2_forecasting.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "data-sci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
